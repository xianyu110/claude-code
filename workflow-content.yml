name: ğŸ“± å°çº¢ä¹¦AIè¯é¢˜æ¯æ—¥é‡‡é›†

on:
  # å®šæ—¶è¿è¡Œï¼šæ¯å¤©åŒ—äº¬æ—¶é—´ä¸Šåˆ9ç‚¹ï¼ˆUTCæ—¶é—´å‡Œæ™¨1ç‚¹ï¼‰
  schedule:
    - cron: '0 1 * * *'
  
  # å…è®¸æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      mode:
        description: 'è¿è¡Œæ¨¡å¼'
        required: true
        default: 'run'
        type: choice
        options:
        - run
        - test
        - upload

  # æ¨é€åˆ°mainåˆ†æ”¯æ—¶è§¦å‘ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
  push:
    branches: [ main ]
    paths:
      - '.github/workflows/daily-ai-scraper.yml'
      - '*.js'

env:
  NODE_ENV: production
  TZ: Asia/Shanghai

jobs:
  scrape-ai-topics:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: ğŸ“¥ æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: ğŸ”§ è®¾ç½®Node.jsç¯å¢ƒ
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: ğŸ“¦ å®‰è£…ä¾èµ–
      run: |
        npm ci
        npx playwright install chromium
    
    - name: ğŸ”‘ é…ç½®ç¯å¢ƒå˜é‡
      run: |
        echo "HEADLESS=true" >> $GITHUB_ENV
        echo "GITHUB_ACTIONS=true" >> $GITHUB_ENV
        echo "FEISHU_SHEET_ID=${{ secrets.FEISHU_SHEET_ID }}" >> $GITHUB_ENV
    
    - name: ğŸ“‚ åˆ›å»ºæ•°æ®ç›®å½•
      run: |
        mkdir -p data
        
    - name: ğŸ¤– è¿è¡ŒAIè¯é¢˜é‡‡é›†
      id: scraping
      run: |
        MODE="${{ github.event.inputs.mode || 'run' }}"
        echo "è¿è¡Œæ¨¡å¼: $MODE"
        
        if [ "$MODE" = "test" ]; then
          node daily_ai_scraper.js test
        else
          node daily_ai_scraper.js
        fi
      env:
        FEISHU_SHEET_ID: ${{ secrets.FEISHU_SHEET_ID }}
    
    - name: ğŸ“Š ç”Ÿæˆè¿è¡ŒæŠ¥å‘Š
      if: always()
      run: |
        echo "## ğŸ¤– å°çº¢ä¹¦AIè¯é¢˜é‡‡é›†æŠ¥å‘Š" > run-report.md
        echo "" >> run-report.md
        echo "**è¿è¡Œæ—¶é—´:** $(date)" >> run-report.md
        echo "**è¿è¡Œæ¨¡å¼:** ${{ github.event.inputs.mode || 'auto' }}" >> run-report.md
        echo "" >> run-report.md
        
        if [ -f "data/daily_scraper.log" ]; then
          echo "### ğŸ“‹ è¿è¡Œæ—¥å¿—" >> run-report.md
          echo "\`\`\`" >> run-report.md
          tail -20 data/daily_scraper.log >> run-report.md
          echo "\`\`\`" >> run-report.md
        fi
    
    - name: ğŸ“¤ ä¸Šä¼ è¿è¡Œäº§ç‰©
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: scraping-results-${{ github.run_number }}
        path: |
          data/
          run-report.md
        retention-days: 30
    
    - name: ğŸ“§ é€šçŸ¥ç»“æœ
      if: always()
      run: |
        if [ "${{ job.status }}" = "success" ]; then
          echo "âœ… AIè¯é¢˜é‡‡é›†ä»»åŠ¡æˆåŠŸå®Œæˆ"
        else
          echo "âŒ AIè¯é¢˜é‡‡é›†ä»»åŠ¡å¤±è´¥"
        fi
        
        if [ -f "data/xiaohongshu_ai_topics_*.csv" ]; then
          echo "ğŸ“Š ç”Ÿæˆçš„CSVæ–‡ä»¶å¯åœ¨Artifactsä¸­ä¸‹è½½"
          echo "ğŸ”— é£ä¹¦è¡¨æ ¼åœ°å€: https://a7uxmstk6o.feishu.cn/base/YUt2bN2O3akgyts2vFdcHFFqneg"
        fi 